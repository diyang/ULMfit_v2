{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from NLPcleansing import prep\n",
    "from customRNNgraph import RNN_build_graph\n",
    "from customRNNgraphBidrection import RNN_bidirect_build_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 18\n",
    "FORWARD_STEPS = 1\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "num_epochs = 20\n",
    "num_hidden = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14640 tweets\n"
     ]
    }
   ],
   "source": [
    "# read data from twitter\n",
    "tweet_data   = pd.read_csv('datasets/us_airline.csv')\n",
    "columns = ['text', 'airline_sentiment']\n",
    "tweet_data_extract = tweet_data[:][columns]\n",
    "tweet_data_extract.dropna()\n",
    "tweet_data_extract[\"clean_text\"] = tweet_data_extract[\"text\"].map(lambda x: prep.text_to_wordlist(x))\n",
    "tweet_data_extract[\"labels\"] = tweet_data_extract[\"airline_sentiment\"].map(lambda x: prep.sentiment_to_label(x, ['neutral', 'positive', 'negative']))\n",
    "print('Found %s tweets' % len(tweet_data_extract[\"clean_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15074 tokens\n"
     ]
    }
   ],
   "source": [
    "# tokenize tweets\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(tweet_data_extract[\"clean_text\"])\n",
    "sequence_tweets = tokenizer.texts_to_sequences(tweet_data_extract[\"clean_text\"])\n",
    "sequence_tweets_pad = pad_sequences(sequence_tweets, MAX_SEQUENCE_LENGTH)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s tokens' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('embedding_matrix.npy'):\n",
    "    embedding_matrix = np.load(\"embedding_matrix.npy\")\n",
    "else:\n",
    "    GloVe_file = \"datasets/glove.6B/glove.6B.300d.txt\"\n",
    "    word2vec_file = \"datasets/glove_word2vec.txt\"\n",
    "    embedding_matrix = prep.word2vec_GloVe(GloVe_file, word2vec_file, word_index=word_index)\n",
    "    np.save(\"embedding_matrix.npy\", embedding_matrix)\n",
    "nb_words = embedding_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of train data: int32\n",
      "dtype of train label: int32\n",
      "shape of train data:  (13176, 18)\n",
      "shape of train label:  (13176,)\n"
     ]
    }
   ],
   "source": [
    "train_seq = sequence_tweets_pad\n",
    "label_seq = tweet_data_extract[\"labels\"]\n",
    "np_train_seq = np.array(list(train_seq), dtype='int32')\n",
    "np_label_seq = np.array(list(label_seq), dtype='int32')\n",
    "\n",
    "########################################\n",
    "## sample train/validation data\n",
    "########################################\n",
    "np.random.seed(1234)\n",
    "perm = np.random.permutation(len(np_train_seq))\n",
    "idx_train = perm[:int(len(np_train_seq)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(np_train_seq)*(1-VALIDATION_SPLIT)):]\n",
    "\n",
    "data_train = np_train_seq[idx_train]\n",
    "data_val = np_train_seq[idx_val]\n",
    "\n",
    "labels_train = np_label_seq[idx_train]\n",
    "labels_val = np_label_seq[idx_val]\n",
    "\n",
    "print('dtype of train data: %s' % data_train.dtype)\n",
    "print('dtype of train label: %s' % labels_train.dtype)\n",
    "\n",
    "print('shape of train data: ', data_train.shape)\n",
    "print('shape of train label: ', labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAN STEP 412\n",
      "VALID STEP 46\n"
     ]
    }
   ],
   "source": [
    "steps_per_train_epoch = int(data_train.shape[0]/BATCH_SIZE)+1\n",
    "steps_per_valid_epoch = int(data_val.shape[0]/BATCH_SIZE)+1\n",
    "print('TRIAN STEP %d' % steps_per_train_epoch)\n",
    "print('VALID STEP %d' % steps_per_valid_epoch)\n",
    "\n",
    "data = {'train_data': data_train, 'train_labels': labels_train, 'embedding': embedding_matrix, \n",
    "        'test_data': data_val, 'test_labels': labels_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/local/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/diyang/Downloads/ULMFiT-Tensorflow/customRNNgraphBidrection.py:72: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
      "WARNING:tensorflow:From /Users/diyang/Downloads/ULMFiT-Tensorflow/customRNNgraphBidrection.py:109: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /opt/local/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /opt/local/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/local/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "data = {'data': data_val, 'embedding': embedding_matrix}\n",
    "g_bidirect_finetune = RNN_bidirect_build_graph(state_size = EMBEDDING_DIM,\n",
    "                                      num_words = nb_words, \n",
    "                                      num_classes = 3, \n",
    "                                      batch_size = BATCH_SIZE,\n",
    "                                      sequence_length = MAX_SEQUENCE_LENGTH,\n",
    "                                      cell_type = 'LN_LSTM',\n",
    "                                      num_layers = 3,\n",
    "                                      init_trainable = False)\n",
    "#pred = g_bidirect.feedforward(data, model_path=\"models/bidirect_lstm/finetune_bidirect/LN_LSTM_bidirect_sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model ...\n",
      "INFO:tensorflow:Restoring parameters from models/bidirect_lstm/finetune_bidirect/LN_LSTM_bidirect_sentiment.ckpt\n",
      "Model Loaded\n",
      "Accuracy: 0.8026\n",
      "Precision: 0.7963\n",
      "Recall: 0.8026\n",
      "F1 Score: 0.7956\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performance\n",
    "import model_evaluation_utils as meu\n",
    "trained_model = \"models/bidirect_lstm/finetune_bidirect/LN_LSTM_bidirect_sentiment.ckpt\"\n",
    "pred = g_bidirect_finetune.feedforward(data, model_path=trained_model)\n",
    "predictions = pd.DataFrame(pred)\n",
    "predictions = list(predictions.idxmax(axis=1))[0:data['data'].shape[0]]\n",
    "labels = list(labels_val)\n",
    "meu.get_metrics(true_labels=labels, \n",
    "                predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
